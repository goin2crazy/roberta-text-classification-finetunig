{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":21733,"databundleVersionId":1408234,"sourceType":"competition"}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import Libraries, Load RoBERTa model and tokenizer ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"import pandas as pd \n\n# Load model directly\nfrom transformers import AutoTokenizer, XLMRobertaModel\n\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.nn import Module\nfrom torch.nn import CrossEntropyLoss as LossFn\nfrom torch.optim import SGD as Optimizer\nimport torch\n\n# show the training progress\nfrom tqdm import tqdm\n\n# split dataset to train and validation \nfrom sklearn.model_selection import train_test_split\n\n# If there's a GPU available...\nif torch.cuda.is_available():    \n\n    # Tell PyTorch to use the GPU.    \n    device = torch.device(\"cuda\")\n\n    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n\n    print('We will use the GPU:', torch.cuda.get_device_name(0))\n\n# If not...\nelse:\n    print('No GPU available, using the CPU instead.')\n    device = torch.device(\"cpu\")    \n\ntokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-base\")\ntokenize = lambda text: tokenizer(text, \n                                  return_tensors = 'pt', \n                                  max_length = 512, \n                                  padding = 'max_length', \n                                  truncation = True)\n\nroberta = XLMRobertaModel.from_pretrained(\"xlm-roberta-base\")","metadata":{"execution":{"iopub.status.busy":"2024-01-04T18:33:30.623180Z","iopub.execute_input":"2024-01-04T18:33:30.623554Z","iopub.status.idle":"2024-01-04T18:33:32.230351Z","shell.execute_reply.started":"2024-01-04T18:33:30.623525Z","shell.execute_reply":"2024-01-04T18:33:32.229321Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"There are 1 GPU(s) available.\nWe will use the GPU: Tesla P100-PCIE-16GB\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Deffine Model Class","metadata":{}},{"cell_type":"code","source":"# Build a model for text classification from 2 text inputs to 3 output labels\nclass CompetitionModel(Module):\n    \"\"\"\n    CompetitionModel class represents a neural network model for text classification using two input texts \n    and producing three output labels.\n    \"\"\"\n    def __init__(self, output_shape, model=None, hidden_size=64):\n        \"\"\"\n        Initializes the CompetitionModel.\n\n        Parameters:\n        - output_shape (int): Number of output classes for classification.\n        - model (optional): Pre-trained transformer model for feature extraction.\n        - hidden_size (int): Size of the hidden layers in the model.\n        \"\"\"\n        # Initialize the torch.nn.Module\n        super().__init__()\n        \n        # Set the default model to 'roberta' if not provided\n        if model is None: \n            model = roberta\n            \n        # Move the model to GPU if available\n        if torch.cuda.is_available(): \n            model.cuda()\n            \n        self.model = model\n        \n        # Linear layer to transform the hidden state of the 'Premise' input\n        self.hidden_premise = torch.nn.Linear(model.config.hidden_size, hidden_size)\n        \n        # Linear layer to transform the hidden state of the 'Hipotesis' input\n        self.hidden_hipotesis = torch.nn.Linear(model.config.hidden_size, hidden_size)\n        \n        # Linear layer for the final classification combining transformed outputs of 'Premise' and 'Hipotesis'\n        self.output_linear = torch.nn.Linear(hidden_size * 2, output_shape)\n        \n        # Softmax activation for obtaining output probabilities\n        self.output_softmax = torch.nn.Softmax(dim=-1)\n    \n    def forward(self,\n                \n                premise_input_ids, \n                premise_attention_mask, \n                \n                hipotesis_input_ids, \n                hipotesis_attention_mask): \n        \"\"\"\n        Forward pass of the model.\n\n        Parameters:\n        - premise_input_ids: Encoded data of 'Premise' column.\n        - premise_attention_mask: Attention mask for 'Premise' input.\n        - hipotesis_input_ids: Encoded data of 'Hipotesis' column.\n        - hipotesis_attention_mask: Attention mask for 'Hipotesis' input.\n\n        Returns:\n        - output: Model predictions after the forward pass.\n        \"\"\"\n        # Get the output of the 'roberta' model for 'Premise' with shape 768\n        premise_roberta_outputs = self.model(premise_input_ids, attention_mask=premise_attention_mask).pooler_output\n        \n        # Get the output of the 'roberta' model for 'Hipotesis' with shape 768\n        hipotesis_roberta_outputs = self.model(hipotesis_input_ids, attention_mask=hipotesis_attention_mask).pooler_output\n        \n        # Transform the hidden state of 'Premise' using a linear layer\n        transformed_premise = self.hidden_premise(premise_roberta_outputs)\n        \n        # Transform the hidden state of 'Hipotesis' using a linear layer\n        transformed_hipotesis = self.hidden_hipotesis(hipotesis_roberta_outputs)\n        \n        # Concatenate the transformed outputs of 'Premise' and 'Hipotesis'\n        concatenated_output = torch.cat([transformed_premise, transformed_hipotesis], axis=1)\n        \n        # Apply a linear layer for the final classification\n        linear_output = self.output_linear(concatenated_output)\n        \n        # Apply softmax activation for obtaining output probabilities\n        output = self.output_softmax(linear_output)\n        \n        return output\n\n# Number of output classes for classification\nnum_classes = 3\n\n# Instantiate the CompetitionModel\nmodel = CompetitionModel(\n    output_shape=num_classes, \n    model=roberta\n)\n\nif torch.cuda.is_available(): \n    model.cuda()","metadata":{"execution":{"iopub.status.busy":"2024-01-04T18:33:32.232613Z","iopub.execute_input":"2024-01-04T18:33:32.232902Z","iopub.status.idle":"2024-01-04T18:33:32.558642Z","shell.execute_reply.started":"2024-01-04T18:33:32.232877Z","shell.execute_reply":"2024-01-04T18:33:32.557614Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"# Load Weights to Model","metadata":{}},{"cell_type":"code","source":"state_dict = torch.load('/kaggle/input/roberta-finetuned-model/model')()\nmodel.load_state_dict(state_dict, strict=False)","metadata":{"execution":{"iopub.status.busy":"2024-01-04T18:33:32.559747Z","iopub.execute_input":"2024-01-04T18:33:32.560040Z","iopub.status.idle":"2024-01-04T18:33:33.361806Z","shell.execute_reply.started":"2024-01-04T18:33:32.560015Z","shell.execute_reply":"2024-01-04T18:33:33.360800Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"_IncompatibleKeys(missing_keys=[], unexpected_keys=['model.embeddings.position_ids'])"},"metadata":{}}]},{"cell_type":"markdown","source":"# Make Predictions","metadata":{}},{"cell_type":"code","source":"# make some visualizations \nfrom tqdm import tqdm ","metadata":{"execution":{"iopub.status.busy":"2024-01-04T18:33:33.364245Z","iopub.execute_input":"2024-01-04T18:33:33.364910Z","iopub.status.idle":"2024-01-04T18:33:33.368995Z","shell.execute_reply.started":"2024-01-04T18:33:33.364875Z","shell.execute_reply":"2024-01-04T18:33:33.368090Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"test_path = '/kaggle/input/contradictory-my-dear-watson/test.csv'\n\ntest_df = pd.read_csv(test_path)","metadata":{"execution":{"iopub.status.busy":"2024-01-04T18:33:33.370138Z","iopub.execute_input":"2024-01-04T18:33:33.370496Z","iopub.status.idle":"2024-01-04T18:33:33.404405Z","shell.execute_reply.started":"2024-01-04T18:33:33.370471Z","shell.execute_reply":"2024-01-04T18:33:33.403704Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"pred_labels:list = []\n\nfor premise, hipothesis in tqdm(zip(test_df.premise.to_list(), test_df.hypothesis.to_list())):\n    hip_enc = tokenize(hipothesis).to(device)\n    premise_enc = tokenize(premise).to(device)\n\n    prediction = model(premise_enc['input_ids'], premise_enc['attention_mask'], hip_enc['input_ids'], hip_enc['attention_mask'])\n    prediction = int(torch.argmax(prediction[0]))\n    pred_labels.append(prediction)","metadata":{"execution":{"iopub.status.busy":"2024-01-04T18:33:33.405383Z","iopub.execute_input":"2024-01-04T18:33:33.405637Z","iopub.status.idle":"2024-01-04T18:37:17.482549Z","shell.execute_reply.started":"2024-01-04T18:33:33.405614Z","shell.execute_reply":"2024-01-04T18:37:17.481683Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"5195it [03:44, 23.18it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"submission = pd.DataFrame({'id': test_df.id, 'prediction': pred_labels})\nsubmission.to_csv('submission.csv', index = False)","metadata":{"execution":{"iopub.status.busy":"2024-01-04T18:37:28.716543Z","iopub.execute_input":"2024-01-04T18:37:28.717157Z","iopub.status.idle":"2024-01-04T18:37:28.737158Z","shell.execute_reply.started":"2024-01-04T18:37:28.717125Z","shell.execute_reply":"2024-01-04T18:37:28.736298Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"submission.prediction.value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-01-04T18:37:31.931603Z","iopub.execute_input":"2024-01-04T18:37:31.931961Z","iopub.status.idle":"2024-01-04T18:37:31.939532Z","shell.execute_reply.started":"2024-01-04T18:37:31.931932Z","shell.execute_reply":"2024-01-04T18:37:31.938613Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"prediction\n0    5195\nName: count, dtype: int64"},"metadata":{}}]}]}